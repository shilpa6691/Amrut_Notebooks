{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Pattuvam_data_till_Aug_2024_corrected.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# Making Standardised Date Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "\n",
    "def standardize_date_format(date_str):\n",
    "    try:\n",
    "        # Use dateutil's parser to automatically recognize and convert various date formats\n",
    "        date_obj = parser.parse(date_str)\n",
    "        # Return the date in DD/MM/YYYY format\n",
    "        return date_obj.strftime('%d/%m/%Y')\n",
    "    except (ValueError, TypeError):\n",
    "        # Handle cases where date_str is not a recognizable date\n",
    "        return 'Unknown'\n",
    "\n",
    "# Assuming you have a DataFrame named data with a 'DATE' column\n",
    "data['Standardized_Date'] = data['DATE'].apply(standardize_date_format)\n",
    "\n",
    "print(\"DataFrame with standardized dates:\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Making Standardised Time Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### For time standardisation\n",
    "\n",
    "def standardize_time(time_str):\n",
    " \n",
    "    time_str = time_str.replace(' ', ':')     #For Replacing the spaces with colons\n",
    "    \n",
    "    \n",
    "        #For cases where time is not in HH:MM format\n",
    "        \n",
    "    if len(time_str) == 1:  # Single digit hour\n",
    "        time_str = f'0{time_str}:00'\n",
    "    elif len(time_str) == 2:  # Only hour \n",
    "        time_str = f'{time_str}:00'\n",
    "    elif len(time_str) == 4:  # Format like HHMM\n",
    "        time_str = f'{time_str[:2]}:{time_str[2:]}'\n",
    "    elif len(time_str) == 5 and ':' not in time_str:  # Format like HHMM\n",
    "        time_str = f'{time_str[:2]}:{time_str[2:]}'\n",
    "    \n",
    "    # Convert to datetime and format as HH:MM\n",
    "    try:\n",
    "        return pd.to_datetime(time_str, format='%H:%M', errors='coerce').strftime('%H:%M')\n",
    "    except ValueError:\n",
    "        return None  # Return None for unparseable formats\n",
    "\n",
    "# Apply the function to the TIME column\n",
    "data['STANDARDIZED_TIME'] = data['TIME'].apply(standardize_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(index=range(2136, 2160), inplace=True) #These indexes shows 31/06/2024 data where June month contains only 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Standardized_Date'] = data['Standardized_Date'].str.replace('2922', '2022')\n",
    "data['Standardized_Date'] = data['Standardized_Date'].str.replace('2032', '2022')\n",
    "data['Standardized_Date'] = data['Standardized_Date'].str.replace('2044', '2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Standardized_Date'] = pd.to_datetime(data['Standardized_Date'], format='DD/MM/YYYY',errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('corrected_date_and_time.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this csv file some special characters are found in some of the column values and that cleaning is done manualy in the csv file. \n",
    "#So the after cleaning all the special characters the new csv file is All_Errors_Corrected.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import datetime\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import re\n",
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('All_Errors_Corrected.csv',parse_dates=['Standardized_Date'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "# Date column cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting issue of 08-2022\n",
    "data[data['Standardized_Date']=='2022-08-31']\n",
    "# at index 18217 repetition started and ends at 18960\n",
    "data.iloc[18216:18300]\n",
    "data = data.drop(data.index[18217:18961])\n",
    "data = data.reset_index(drop=True)\n",
    "data.shape\n",
    "# data[data['Standardized_Date']=='2022-08-31']\n",
    " \n",
    "# # correcting the date where the two hours where misplaced\n",
    "data[data['Standardized_Date']=='2022-08-20']\n",
    "data.iloc[17927:17929]\n",
    "# Replace the dates at indices 17927 and 17929 with the date from index 17926\n",
    "data.loc[[17927, 17929], 'Standardized_Date'] = data.loc[17926,'Standardized_Date']\n",
    "data.loc[[17928], 'STANDARDIZED_TIME'] = '1:00'\n",
    " \n",
    "# # correcting date 2023-10-09 which was misplaced as 2023-10-10 \n",
    "data[data['Standardized_Date']=='2023-10-11']\n",
    "data.iloc[7440:7464]\n",
    "# Replace the date in the column for the range of indices 7440 to 7464\n",
    "data.loc[7440:7463, 'Standardized_Date'] = pd.Timestamp('2023-10-09')\n",
    " \n",
    "# # 2023-11-09 is misplaced as 2023 -11-10 and 2023-11-10 is misplaced as 2023 -11-11\n",
    "data[data['Standardized_Date']=='2023-11-10']\n",
    "data.iloc[6720:6743]\n",
    "data.loc[6720:6743, 'Standardized_Date'] = pd.Timestamp('2023-11-09')\n",
    "data[data['Standardized_Date']=='2023-11-11']\n",
    "data.iloc[6744:6767]\n",
    "data.loc[6744:6767, 'Standardized_Date'] = pd.Timestamp('2023-11-10')\n",
    " \n",
    "# # 2022-03-28 *48 since 2022 -05-28 is misplaced as 2022-03-2028\n",
    "data[data['Standardized_Date']=='2022-03-28']\n",
    "data.iloc[21790:21805]\n",
    "# Replace the date in the column for the range of indices 20330 to 20354\n",
    "data.loc[20329:20352, 'Standardized_Date'] = pd.Timestamp('2022-05-28')\n",
    " \n",
    "# # 2022-05-16 (*25) since the 0:00 of  2022-05-15 was given this date,2023-05-14 the 0:00 of 2023-05-13 was given this date, the 0:00 of  2022-06-15 was given date 2022-06-16,same issue in 2023-01-07,same at 2022-07-16,same at 2022-12-07,same at 2022-04-16,same at 2022-12-01,same at 2022-03-16\n",
    "# Loop through the DataFrame and check rows where time is '0:00'\n",
    " \n",
    "for idx in data.index:\n",
    "    if data.loc[idx, 'STANDARDIZED_TIME'] == '0:00':\n",
    "        # Check the previous row's date and time\n",
    "        if idx > 0:  # Ensure we are not checking the first row\n",
    "            prev_date = data.loc[idx - 1, 'Standardized_Date']\n",
    "            prev_time = data.loc[idx - 1, 'STANDARDIZED_TIME']\n",
    "            # If the previous row's time is '23:00' and the dates are different\n",
    "            if (prev_time == '23:00') and (prev_date != data.loc[idx, 'Standardized_Date']):\n",
    "                # Reassign the current row's date to the previous date\n",
    "                data.loc[idx, 'Standardized_Date'] = prev_date\n",
    "# Dropping the error row with index 14544\n",
    "data = data.drop(index=14544)\n",
    "# Reset the index and drop the old index\n",
    "data = data.reset_index(drop=True)\n",
    " \n",
    "data[data['Standardized_Date']=='2022-08-28']\n",
    "# Change the time at index 18126 to '7:00'\n",
    "data.loc[18126, 'STANDARDIZED_TIME'] = '7:00'\n",
    " \n",
    "#  2023-02-06 was also given to 3:00 of 2022-02-06\n",
    "data[data['Standardized_Date']=='2022-02-06']\n",
    "data.iloc[22005:22015]\n",
    "data.loc[22009, 'Standardized_Date'] = pd.Timestamp('2022-02-06')\n",
    "data.loc[22010, 'Standardized_Date'] = pd.Timestamp('2022-02-06')\n",
    " \n",
    "# instead of 2023-08-10 the date 2023-10-08 is given at 20:00\n",
    "data[data['Standardized_Date']=='2023-10-08']\n",
    "data.loc[12619, 'Standardized_Date'] = pd.Timestamp('2023-08-10')\n",
    " \n",
    "# 2022-06-04 was placed at 1:00 of 2022-07-04\n",
    "data[data['Standardized_Date']=='2022-06-04']\n",
    "data.loc[18288, 'Standardized_Date'] = pd.Timestamp('2022-07-04')\n",
    " \n",
    "# 2023-03-20 at 2:00 was placed instead of 2023-03-21\n",
    "data[data['Standardized_Date']=='2023-03-20']\n",
    "data.loc[12121, 'Standardized_Date'] = pd.Timestamp('2023-03-21')\n",
    " \n",
    "data[data['Standardized_Date']=='2023-12-03']\n",
    "data.loc[11912, 'Standardized_Date'] = pd.Timestamp('2023-03-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Remarks Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.REMARKS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['REMARKS'] = data['REMARKS'].str.lower()\n",
    "Rem = data.REMARKS.value_counts().reset_index()\n",
    "# Rem.index = Rem.index.lower\n",
    "Rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['REMARKS']=='maintenance work at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMARKS\n",
    "#22697\t2022-02-03\t17:00\t0.0\t2.40\t0.0\t0.0\tmaintenance work at \n",
    "#22698\t2022-02-03\t18:00\t0.0\t2.09\t0.0\t0.0\tintake\n",
    "\n",
    "indices_maint = list(range(21952, 21954)) + \\\n",
    "          list(range(22187, 22189))\n",
    "data.loc[indices_maint,'REMARKS'] = 'maintanance work at intake'\n",
    "rows = data.loc[indices_maint]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = ['1','3','pumping started','power failure at 7.28 to 7.36 pm','power failure at wtp 6.03 to6.40am']\n",
    "for i in range(len(data)):\n",
    "    if data.loc[i,'REMARKS'] in list1:\n",
    "        data.loc[i,'REMARKS'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['REMARKS']=='pumping stoped due to intake')|(data['REMARKS']=='pumping sopped due to inake')|(data['REMARKS']=='pumping stopped due to intake')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMARKS\n",
    "# 19039\t2022-07-04\t7:00\t0.0\t2.94\t0.00\t0.0\tpumping stoped due to intake\n",
    "# 19040\t2022-07-04\t8:00\t0.0\t2.64\t0.00\t0.0\tsump level low\n",
    "\n",
    "indices_sump = list(range(18294, 18296)) + \\\n",
    "          list(range(18309, 18311)) + \\\n",
    "          list(range(18328, 18330)) + \\\n",
    "          list(range(18341, 18343)) + \\\n",
    "          list(range(18366, 18368))\n",
    "data.loc[indices_sump,'REMARKS'] = 'intake sump level low'\n",
    "rows = data.loc[indices_sump]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMARKS\n",
    "# 17218\t2022-09-20\t10:00\t0.0\t3.38\t0.0\t0.0\tpumping sopped due to inake\n",
    "# 17219\t2022-09-20\t11:00\t0.0\t3.34\t0.0\t0.0\tchamber cleaning\n",
    "\n",
    "indices_chamber = list(range(17217, 17219))\n",
    "data.loc[indices_chamber,'REMARKS'] = 'intake chamber cleaning'\n",
    "rows = data.loc[indices_chamber]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.REMARKS=='pumping stopped due to']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMARKS\n",
    "# 16257\t2022-10-11\t9:00\t0.00\t2.72\t0.00\t0.00\tpumping stopped due to\n",
    "# 16258\t2022-10-11\t10:00\t0.00\t2.66\t0.00\t0.00\tintake chamber cleaning\n",
    "\n",
    "indices_chamber = list(range(16256, 16258)) + \\\n",
    "          list(range(17264, 17266)) + \\\n",
    "          list(range(17913, 17915)) + \\\n",
    "          list(range(17937, 17939)) + \\\n",
    "          list(range(17959, 17961)) + \\\n",
    "          list(range(17986, 17988)) + \\\n",
    "          list(range(18033, 18035)) + \\\n",
    "          list(range(18057, 18059)) \n",
    "#           list(range(19289, 19291)) + \\\n",
    "#           list(range(21069, 21071)) + \\\n",
    "#           list(range(21103, 21105)) \n",
    "data.loc[indices_chamber,'REMARKS'] = 'intake chamber cleaning'\n",
    "rows = data.loc[indices_chamber]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMARKS\n",
    "# 20034\t2022-06-14\t18:00\t0.0\t3.12\t0.0\t0.0\tpumping stopped due to\n",
    "# 20035\t2022-06-14\t19:00\t0.0\t3.10\t0.0\t0.0\tpipe line broken at taliparamba\n",
    "# 21814\t2022-04-27\t22:00\tNaN\tNaN\tNaN\t0.0\tpumping stopped due to\n",
    "# 21815\t2022-04-27\t23:00\tNaN\tNaN\tNaN\t0.0\tmaintenance at thaliparamba\n",
    "\n",
    "indices_thaliparambu =list(range(19289, 19291))\n",
    "data.loc[indices_thaliparambu,'REMARKS'] = 'pipe line broken at Thaliparamba'\n",
    "\n",
    "indices_thaliparambu =list(range(21069, 21071))\n",
    "data.loc[indices_thaliparambu,'REMARKS'] = 'maintanance at Thaliparamba'\n",
    "\n",
    "\n",
    "## REMARKS\n",
    "# 21848\t2022-04-29\t8:00\t0.0\t2.0\t0.0\t0.0\tpumping stopped due to\n",
    "# 21849\t2022-04-29\t9:00\t0.0\t2.0\t0.0\t0.0\tmaintenance work at intake\n",
    "\n",
    "indices_maintain =list(range(21103, 21105))\n",
    "data.loc[indices_maintain,'REMARKS'] = 'maintanance work at intake'\n",
    "rows = data.loc[indices_maintain]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.REMARKS=='power failed @9.45 to 2.25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[13328,'REMARKS'] = np.nan\n",
    "data.loc[13329,'REMARKS'] = 'power failure at intake and WTP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.REMARKS=='permitted power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMARKS\n",
    "# 23001\t2022-02-16\t9:00\t3604.19\t3.33\t2781.45\t3488.14\tpermitted power\n",
    "# 23002\t2022-02-16\t10:00\t0.00\t0.00\t0.00\t0.00\tfailure at wtp\n",
    "\n",
    "indices_wtp_power =list(range(22256, 22258)) \n",
    "data.loc[indices_wtp_power,'REMARKS'] = 'power failure at WTP'\n",
    "data.loc[22256,'REMARKS'] = np.nan\n",
    "rows = data.loc[indices_wtp_power]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.REMARKS=='informed power failure at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMARKS\n",
    "# 22497\t2022-03-26\t9:00\tNaN\tNaN\tNaN\t0.0\tinformed power failure at\n",
    "# 22498\t2022-03-26\t10:00\tNaN\tNaN\tNaN\t0.0\tintake\n",
    "\n",
    "indices_intake_power = [21752,21753]\n",
    "data.loc[indices_intake_power,'REMARKS'] = 'power failure at intake'\n",
    "rows = data.loc[indices_intake_power]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.REMARKS=='rw pumping stopped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[5173:5175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.REMARKS=='power failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20938\t2022-05-22\t10:00\t2475.82\t3.92\t2842.36\t2396.10\tpower failure\t\n",
    "data.loc[20193,'REMARKS'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[5172:5195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5173\t2024-01-06\t14:00\t1265.45\t3.92\t0.00\t1224.70\trw pumping stopped\n",
    "data.loc[5173,'REMARKS'] = np.nan\n",
    "data.loc[5174,'REMARKS'] = 'intake pumping stopped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['REMARKS'] = data['REMARKS'].str.lower()\n",
    "Rem = data.REMARKS.value_counts().reset_index()\n",
    "# Rem.index = Rem.index.lower\n",
    "Rem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## Categorize REMARKS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_remarks(data):\n",
    "    \"\"\"\n",
    "    Categorizes the remarks column based on specific conditions:\n",
    "    1. 'Power Failure at Intake' if:\n",
    "       - Contains 'intake' (case-insensitive)\n",
    "       - Contains 'power' (case-insensitive)\n",
    "       - Does not contain 'wtp' (case-insensitive)\n",
    "    \n",
    "    2. 'Power Failure at WTP' if:\n",
    "       - Does not contain 'intake'\n",
    "       - Contains 'power' (case-insensitive)\n",
    "       - Contains 'wtp' (case-insensitive)\n",
    "    \"\"\"\n",
    "    \n",
    "    def categorize(row):\n",
    "        remarks = row['REMARKS']\n",
    "        raw_water = row['RAW WATER FLOW IN m3/h']\n",
    "        clear_water_pumping = row['CLEAR WATER PUMPING FLOW m3/h']\n",
    "        if pd.notna(remarks):\n",
    "            remarks_lower = remarks.lower()\n",
    "            if ('intake' in remarks_lower and ('power' in remarks_lower or 'failure' in remarks_lower) and 'wtp' not in remarks_lower) or (('power' in remarks_lower or 'failure' in remarks_lower) and 'wtp' not in remarks_lower and (raw_water == 0.0 or pd.isna(raw_water)) and not pd.isna(clear_water_pumping) and clear_water_pumping != 0.0):\n",
    "                return 'Power Failure at Intake'\n",
    "            elif ('intake' not in remarks_lower and ('power' in remarks_lower or 'failure' in remarks_lower) and 'wtp' in remarks_lower) or (('power' in remarks_lower or 'failure' in remarks_lower) and 'intake' not in remarks_lower and not pd.isna(raw_water) and raw_water !=0.0 and (clear_water_pumping == 0.0 or pd.isna(clear_water_pumping))):\n",
    "                return 'Power Failure at WTP'\n",
    "            elif ('intake' in remarks_lower and ('power' in remarks_lower or 'failure' in remarks_lower) and 'wtp' in remarks_lower) or ('intake' not in remarks_lower and 'wtp' not in remarks_lower and ('power' in remarks_lower or 'failure' in remarks_lower) and (raw_water == 0.0 or pd.isna(raw_water)) and (clear_water_pumping == 0.0 or pd.isna(clear_water_pumping))):\n",
    "                return 'Power Failure at intake and WTP'\n",
    "            elif (('cleaning' in remarks_lower or 'wash' in remarks_lower) and 'intake' in remarks_lower):\n",
    "                return 'intake cleaning'\n",
    "            elif 'maint' in remarks_lower and 'intake' in remarks_lower:\n",
    "                return 'maintanance at intake'\n",
    "            elif 'maint' in remarks_lower and 'thaliparamba' in remarks_lower or 'taliparamba' in remarks_lower:\n",
    "                return 'maintanance at Thaliparamba'\n",
    "            elif 'maint' in remarks_lower and 'distribution' in remarks_lower:\n",
    "                return 'distribution line maintanance'\n",
    "            elif 'maint' in remarks_lower:\n",
    "                return 'maintanance'\n",
    "#             elif 'intake sump level low' in remarks_lower:\n",
    "#                 return 'intake sump level low'\n",
    "#             elif 'energy auditing' in remarks_lower:\n",
    "#                 return 'energy auditing'\n",
    "#             elif 'issue at thaliparambu' in remarks_lower:\n",
    "#                 return 'issue at thaliparambu'\n",
    "            elif 'cleaning' in remarks_lower and ('twr' in remarks_lower or 'wtp' in remarks_lower):\n",
    "                return 'WTP cleaning'\n",
    "#             elif 'intake pumping stopped' in remarks_lower:\n",
    "#                 return 'intake pumping stopped'\n",
    "            elif 'plc complaint' in remarks_lower:\n",
    "                return 'complaint at WTP'\n",
    "            else:\n",
    "                return remarks_lower\n",
    "            \n",
    "#         return ''\n",
    "\n",
    "    # Apply the categorization function to each row\n",
    "    data['remarks category'] = data.apply(categorize, axis=1)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = categorize_remarks(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['remarks category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['remarks category']=='maintanance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['remarks category'].isna()].REMARKS.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_list = list(df[df['remarks category'].isna()].REMARKS.unique())\n",
    "remain_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## Filling 'remarks category' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill NaN values in 'remarks category' based on the conditions\n",
    "def fill_remarks_category(df):\n",
    "    previous_remark = None\n",
    "#     remarks_flag=False\n",
    "    for i in range(len(df)):\n",
    "        current_remark = df.loc[i, 'remarks category']\n",
    "        raw_water_flow = df.loc[i, 'RAW WATER FLOW IN m3/h']\n",
    "        clear_water_pumping_flow = df.loc[i, 'CLEAR WATER PUMPING FLOW m3/h']\n",
    "        # Check if 'remarks category' is NaN and if the previous row had a non-NaN remark\n",
    "        if pd.isna(current_remark):\n",
    "            # Check if raw water and treated water columns are 0 or NaN\n",
    "            if ((raw_water_flow == 0 or pd.isna(raw_water_flow)) and (clear_water_pumping_flow == 0 or pd.isna(clear_water_pumping_flow))):# or (('intake' in previous_remark) and (raw_water_flow == 0) and (clear_water_pumping_flow != 0)) or (('WTP' in previous_remark) and (raw_water_flow != 0) and (clear_water_pumping_flow == 0)):\n",
    "                # Fill the current NaN remark with the previous non-NaN remark\n",
    "                df.loc[i, 'remarks category'] = previous_remark\n",
    "            elif previous_remark is not None and (('intake' in previous_remark and 'WTP' not in previous_remark and (raw_water_flow == 0 or pd.isna(raw_water_flow)) and clear_water_pumping_flow != 0) or ('WTP' in previous_remark and 'intake' not in previous_remark and raw_water_flow != 0 and (clear_water_pumping_flow == 0 or pd.isna(clear_water_pumping_flow)))):\n",
    "                df.loc[i, 'remarks category'] = previous_remark\n",
    "            elif previous_remark is not None and 'complaint at WTP' in previous_remark and (raw_water_flow == 0 or pd.isna(raw_water_flow)):\n",
    "                df.loc[i, 'remarks category'] = previous_remark\n",
    "#             elif previous_remark is not None and 'WTP cleaning' in previous_remark and (raw_water_flow == 0 or pd.isna(raw_water_flow)) and (clear_water_flow == 0 or pd.isna(clear_water_flow)):\n",
    "#                 df.loc[i, 'remarks category'] = previous_remark\n",
    "            else:\n",
    "                previous_remark = current_remark\n",
    "        else:\n",
    "            # Update the previous_remark if the current remark is not NaN\n",
    "            previous_remark = current_remark\n",
    " \n",
    "    return df\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the DataFrame\n",
    "df_filled = fill_remarks_category(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled['remarks category']=='WTP cleaning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [22818,22819]\n",
    "df_filled.loc[list1,'remarks category'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled['remarks category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled['remarks category']=='maintanance'].REMARKS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled.REMARKS=='stopped for maintanance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[12696:12716]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[5150:5189]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled['remarks category']=='complaint at WTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[6200:6234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[(df_filled['RAW WATER FLOW IN m3/h'].isna())&(df_filled['CLEAR WATER SUMP LEVEL IN Meter'].isna())&(df_filled['CLEAR WATER PUMPING FLOW m3/h'].isna())&(df_filled['TREATED WATER PRODUCTION IN m3/h']==0.0)&(df_filled['REMARKS'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[(df_filled['RAW WATER FLOW IN m3/h'].isna())&(df_filled['CLEAR WATER SUMP LEVEL IN Meter'].isna())&(df_filled['CLEAR WATER PUMPING FLOW m3/h'].isna())&(df_filled['TREATED WATER PRODUCTION IN m3/h']==0.0)&(df_filled['remarks category'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filled.to_excel('df_filled.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "# Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the value at index 3355(13489.25)\n",
    "df_filled.loc[3355, 'RAW WATER FLOW IN m3/h'] = 3489.25\n",
    "\n",
    "# Change the value at index 6791(62411.58)\n",
    "df_filled.loc[6791, 'RAW WATER FLOW IN m3/h'] = 2411.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_water_outlier_ffill(data, column_name1,column_name2,column_name3, threshold=4000):\n",
    " \n",
    "    for i in range(1, len(data)):\n",
    "        # If the value is greater than the threshold\n",
    "        if data.loc[i, column_name1] >= threshold:\n",
    "            # Forward fill using the previous value\n",
    "            data.loc[i, column_name1] = data.loc[i, column_name1] * 0.1\n",
    "            \n",
    "            data.loc[i,'TREATED WATER PRODUCTION IN m3/h'] = (data.loc[i, column_name1]*0.967).round(2)\n",
    "    for i in range(1, len(data)):\n",
    "        # If the value is greater than the threshold\n",
    "        if data.loc[i, column_name2] > 5:\n",
    "            # Forward fill using the previous value\n",
    "            data.loc[i, column_name2] = data.loc[i-1, column_name2]\n",
    "            \n",
    "    for i in range(1, len(data)):\n",
    "        # If the value is greater than the threshold\n",
    "        if data.loc[i, column_name3] > threshold:\n",
    "            \n",
    "            # Forward fill using the previous value\n",
    "            data.loc[i, column_name3] = data.loc[i-1, column_name3]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = raw_water_outlier_ffill(df_filled, 'RAW WATER FLOW IN m3/h','CLEAR WATER SUMP LEVEL IN Meter','CLEAR WATER PUMPING FLOW m3/h')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "# Null value cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[(df_filled['RAW WATER FLOW IN m3/h'].isna()) & (df_filled['CLEAR WATER SUMP LEVEL IN Meter'].isna()) & (df_filled['CLEAR WATER PUMPING FLOW m3/h'].isna()) & (df_filled['TREATED WATER PRODUCTION IN m3/h']==0) & (df_filled['remarks category']).isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled['TREATED WATER PRODUCTION IN m3/h'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.loc[12619, 'TREATED WATER PRODUCTION IN m3/h'] = 3153.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[12618:12621]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled['RAW WATER FLOW IN m3/h'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.loc[df_filled['remarks category'].notnull()] = df_filled.loc[df_filled['remarks category'].notnull()].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled['RAW WATER FLOW IN m3/h'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled['CLEAR WATER PUMPING FLOW m3/h'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_to_fill = [2779, 8638, 8687, 23310]\n",
    "df_filled.loc[indexes_to_fill, 'CLEAR WATER PUMPING FLOW m3/h'] = df_filled['CLEAR WATER PUMPING FLOW m3/h'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled['CLEAR WATER PUMPING FLOW m3/h'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled['CLEAR WATER SUMP LEVEL IN Meter'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_to_fill = [321, 2604, 2605, 2606, 4911]\n",
    "df_filled.loc[indexes_to_fill, 'CLEAR WATER SUMP LEVEL IN Meter'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled['CLEAR WATER SUMP LEVEL IN Meter'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled['STANDARDIZED_TIME'] = pd.to_datetime(df_filled['STANDARDIZED_TIME'],format='%H:%M').dt.time\n",
    "df_filled=df_filled.sort_values(by=['Standardized_Date','STANDARDIZED_TIME'],ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.dtypes(#.dt.time attribute extracts time values as Python datetime.time objects, which are not one of the native Pandas types like\n",
    "#datetime64 . Pandas treats datetime.time objects as object data type.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled['REMARKS'].fillna('No Remarks', inplace=True)\n",
    "df_filled['REMARKS'].replace(0,'No Remarks',inplace=True)\n",
    "df_filled['remarks category'].fillna('No Remarks', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[df_filled['CLEAR WATER SUMP LEVEL IN Meter'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[8735:8739]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled[15311:15314]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_to_fill = [8736,15312]\n",
    "# # columns_to_fill = ['RAW WATER FLOW IN m3/h', 'CLEAR WATER PUMPING FLOW m3/h', 'CLEAR WATER SUMP LEVEL IN Meter']\n",
    "# # df_filled.loc[indexes_to_fill, columns_to_fill] = df_filled[columns_to_fill].bfill()\n",
    "df_filled.loc[indexes_to_fill] = df_filled.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_in_ML= ['RAW WATER FLOW IN m3/h','CLEAR WATER PUMPING FLOW m3/h',\n",
    "       'TREATED WATER PRODUCTION IN m3/h']\n",
    "df_filled[flow_in_ML]= df_filled[flow_in_ML]*0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.rename(columns={'RAW WATER FLOW IN m3/h': 'RAW WATER FLOW IN ML','CLEAR WATER PUMPING FLOW m3/h':'CLEAR WATER PUMPING FLOW ML','TREATED WATER PRODUCTION IN m3/h':'TREATED WATER PRODUCTION IN ML'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filled.to_excel('final_pattuvam_cleaned_data.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
