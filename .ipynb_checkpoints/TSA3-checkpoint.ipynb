{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('final_data_in_ML.csv',parse_dates=['Standardized_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['Standardized_Date','RAW WATER FLOW IN ML',\n",
    "       'CLEAR WATER SUMP LEVEL IN Meter', 'CLEAR WATER PUMPING FLOW ML',\n",
    "       'TREATED WATER PRODUCTION IN ML', 'remarks category']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['remarks category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include=object).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_en = LabelEncoder()\n",
    "\n",
    "a = ['remarks category']\n",
    "for i in a:\n",
    "    data[i] = label_en.fit_transform(data[i])\n",
    "    # Display the mapping of labels to original values\n",
    "    label_mapping = dict(zip(label_en.classes_, label_en.transform(label_en.classes_)))\n",
    "    print(f\"Label mapping for column '{i}':\")\n",
    "    print(label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('Standardized_Date', inplace=True)\n",
    "df=data[['CLEAR WATER PUMPING FLOW ML',\n",
    "        'remarks category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['remarks category'].plot(kind='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['remarks category'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(data.corr(),vmin = -0.99,vmax = 0.99,cmap='YlGnBu',linewidths =0.1,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['TREATED WATER PRODUCTION IN ML'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['CLEAR WATER PUMPING FLOW ML']\n",
    "X=data.drop(['CLEAR WATER PUMPING FLOW ML'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max = MinMaxScaler(feature_range =(0,1))\n",
    "X = min_max.fit_transform(X)\n",
    "X=pd.DataFrame(X)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into train and test \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=42,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r2)\n",
    "y_pred[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since we have continuous values in our target variable,and classification models won't perform the continuous variables, so splitting the target column values into 0,1,2 and 3 and 4\n",
    "y[(y>0)&(y<=2)]=0\n",
    "y[(y>2)&(y<=4)]=1\n",
    "y[(y>4)&(y<=6)]=2\n",
    "y[(y>6)&(y<=8)]=3\n",
    "y[(y>8)&(y<=10)]=4\n",
    "#Checking the imbalance of the dataset\n",
    "y.value_counts(normalize=True).to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we can see that the data is highly imbalanced. \n",
    "#So we have to make the dataset balanced\n",
    "#Here we will go for oversampling as in undersampling data drop will be there .\n",
    "#Oversampling will create new examples in minority class and can keep the data in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smt=SMOTE(k_neighbors=2)\n",
    "X_os, y_os = smt.fit_resample(X, y)\n",
    "sns.countplot(y_os)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_os.value_counts(normalize=True).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into train and test \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_os,y_os,random_state=42,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import  classification_report\n",
    "logit_reg=LogisticRegression()\n",
    "model=logit_reg.fit(X_train,y_train)\n",
    "predictions1=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results from logistic regression are as below\")\n",
    "log_result = classification_report(predictions1,y_test,output_dict=True)\n",
    "log_result = pd.DataFrame(log_result).transpose()\n",
    "log_result.style.background_gradient(cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_model=DecisionTreeClassifier()\n",
    "dt_model.fit(X_train,y_train)\n",
    "predictions2=dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results from Decision Tree are as below\")\n",
    "DT_result = classification_report(predictions2,y_test,output_dict=True)\n",
    "DT_result = pd.DataFrame(DT_result).transpose()\n",
    "DT_result.style.background_gradient(cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "predictions5 = rf.predict(X_test)\n",
    "predictions5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results from Random Forest are as below\")\n",
    "RF_result = classification_report(predictions5,y_test,output_dict=True)\n",
    "RF_result = pd.DataFrame(RF_result).transpose()\n",
    "RF_result.style.background_gradient(cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB = GradientBoostingClassifier()\n",
    "model = GB.fit(X_train,y_train)\n",
    "predictions6 = model.predict(X_test)\n",
    "print(\"Results from Gradient Boosting are as below\")\n",
    "GB_result = classification_report(predictions6,y_test,output_dict=True)\n",
    "GB_result = pd.DataFrame(GB_result).transpose()\n",
    "GB_result.style.background_gradient(cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "# Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "AD=AdaBoostClassifier()\n",
    "AD_model= AD.fit(X_train , y_train)\n",
    "predictions7=AD_model.predict(X_test)\n",
    "print(\"Results from ADA booster are as below\")\n",
    "AD_result = classification_report(predictions7,y_test,output_dict=True)\n",
    "AD_result = pd.DataFrame(AD_result).transpose()\n",
    "AD_result.style.background_gradient(cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "GNB=GaussianNB()\n",
    "GNB_model=GNB.fit(X_train , y_train)\n",
    "predictions8=GNB_model.predict(X_test)\n",
    "print(\"Results from Gaussian Naive bayer are as below\")\n",
    "GNB_result = classification_report(predictions8,y_test,output_dict=True)\n",
    "GNB_result = pd.DataFrame(GNB_result).transpose()\n",
    "GNB_result.style.background_gradient(cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "# BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "BC=BaggingClassifier()\n",
    "BC_model=BC.fit(X_train , y_train)\n",
    "predictions9=BC_model.predict(X_test)\n",
    "print(\"Results from Bagging classifier are as below\")\n",
    "BC_result = classification_report(predictions9,y_test,output_dict=True)\n",
    "BC_result = pd.DataFrame(BC_result).transpose()\n",
    "BC_result.style.background_gradient(cmap=\"BuPu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
